maxPages
key<-"c1b06598bf284957a1ddd98cdda82dff"
term <- "twin+towers+terrorism" # Need to use + to string together separate words
begin_date <- "19890419"
end_date <- "19890901"
baseurl <- paste0("http://api.nytimes.com/svc/search/v2/articlesearch.json?q=",term,
"&begin_date=",begin_date,"&end_date=",end_date,
"&facet_filter=true&api-key=",key, sep="")
initialQuery <- fromJSON(baseurl)
maxPages <- round((initialQuery$response$meta$hits[1] / 10)-1)
maxPages
key<-"c1b06598bf284957a1ddd98cdda82dff"
term <- "George+Bush+war" # Need to use + to string together separate words
begin_date <- "19890419"
end_date <- "20040901"
baseurl <- paste0("http://api.nytimes.com/svc/search/v2/articlesearch.json?q=",term,
"&begin_date=",begin_date,"&end_date=",end_date,
"&facet_filter=true&api-key=",key, sep="")
initialQuery <- fromJSON(baseurl)
maxPages <- round((initialQuery$response$meta$hits[1] / 10)-1)
maxPages
pages <- list()
for(i in 0:maxPages){
nytSearch <- fromJSON(paste0(baseurl, "&page=", i), flatten = TRUE) %>% data.frame()
message("Retrieving page ", i)
pages[[i+1]] <- nytSearch
Sys.sleep(1)
}
key<-"c1b06598bf284957a1ddd98cdda82dff"
term <- "Hillary+Clinton+elections+2016" # Need to use + to string together separate words
begin_date <- "19890419"
end_date <- "20170901"
baseurl <- paste0("http://api.nytimes.com/svc/search/v2/articlesearch.json?q=",term,
"&begin_date=",begin_date,"&end_date=",end_date,
"&facet_filter=true&api-key=",key, sep="")
initialQuery <- fromJSON(baseurl)
maxPages <- round((initialQuery$response$meta$hits[1] / 10)-1)
maxPages
if (maxPages>20){
maxPages<-20
pages <- list()
for(i in 0:maxPages){
nytSearch <- fromJSON(paste0(baseurl, "&page=", i), flatten = TRUE) %>% data.frame()
message("Retrieving page ", i)
pages[[i+1]] <- nytSearch
Sys.sleep(1)
}
}
allNYTSearch <- rbind_pages(pages)
# Visualize coverage by section
allNYTSearch %>%
group_by(response.docs.type_of_material) %>%
summarize(count=n()) %>%
mutate(percent = (count / sum(count))*100) %>%
ggplot() +
geom_bar(aes(y=percent, x=response.docs.type_of_material, fill=response.docs.type_of_material), stat = "identity") + coord_flip()
key<-"c1b06598bf284957a1ddd98cdda82dff"
term <- "bill+clinton+monica" # Need to use + to string together separate words
begin_date <- "19890419"
end_date <- "20170901"
baseurl <- paste0("http://api.nytimes.com/svc/search/v2/articlesearch.json?q=",term,
"&begin_date=",begin_date,"&end_date=",end_date,
"&facet_filter=true&api-key=",key, sep="")
initialQuery <- fromJSON(baseurl)
maxPages <- round((initialQuery$response$meta$hits[1] / 10)-1)
maxPages
if (maxPages>20){
maxPages<-20
pages <- list()
for(i in 0:maxPages){
nytSearch <- fromJSON(paste0(baseurl, "&page=", i), flatten = TRUE) %>% data.frame()
message("Retrieving page ", i)
pages[[i+1]] <- nytSearch
Sys.sleep(1)
}
}
allNYTSearch <- rbind_pages(pages)
# Visualize coverage by section
allNYTSearch %>%
group_by(response.docs.type_of_material) %>%
summarize(count=n()) %>%
mutate(percent = (count / sum(count))*100) %>%
ggplot() +
geom_bar(aes(y=percent, x=response.docs.type_of_material, fill=response.docs.type_of_material), stat = "identity") + coord_flip()
library(httr)
library(jsonlite)
library(rjson)
term <- "bill+clinton+monica" # Need to use + to string together separate words
begin_date <- "19890419"
end_date <- "20170901"
baseurl <- paste0("http://api.nytimes.com/svc/search/v2/articlesearch.json?q=",term,
"&begin_date=",begin_date,"&end_date=",end_date,
"&facet_filter=true&api-key=",key, sep="")
initialQuery <- fromJSON(baseurl)
maxPages <- round((initialQuery$response$meta$hits[1] / 10)-1)
baseurl <- paste0("http://api.nytimes.com/svc/search/v2/articlesearch.json?q=",term,
"&begin_date=",begin_date,"&end_date=",end_date,
"&facet_filter=true&api-key=",key, sep="")
initialQuery <- fromJSON(baseurl)
initialQuery <- fromJSON(baseurl)
maxPages <- round((initialQuery$response$meta$hits[1] / 10)-1)
maxPages
if (maxPages>20){
maxPages<-20
pages <- list()
for(i in 0:maxPages){
nytSearch <- fromJSON(paste0(baseurl, "&page=", i), flatten = TRUE) %>% data.frame()
message("Retrieving page ", i)
pages[[i+1]] <- nytSearch
Sys.sleep(1)
}
}
library(httr)
library(jsonlite)
library(rjson)
library(tidyverse)
if (maxPages>20){
maxPages<-20
pages <- list()
for(i in 0:maxPages){
nytSearch <- fromJSON(paste0(baseurl, "&page=", i), flatten = TRUE) %>% data.frame()
message("Retrieving page ", i)
pages[[i+1]] <- nytSearch
Sys.sleep(1)
}
}
allNYTSearch <- rbind_pages(pages)
# Visualize coverage by section
allNYTSearch %>%
group_by(response.docs.type_of_material) %>%
summarize(count=n()) %>%
mutate(percent = (count / sum(count))*100) %>%
ggplot() +
geom_bar(aes(y=percent, x=response.docs.type_of_material, fill=response.docs.type_of_material), stat = "identity") + coord_flip()
key<-"c1b06598bf284957a1ddd98cdda82dff"
term <- "bill+clinton+monica" # Need to use + to string together separate words
begin_date <- "19890419"
end_date <- "20170901"
baseurl <- paste0("http://api.nytimes.com/svc/search/v2/articlesearch.json?q=",term,
"&begin_date=",begin_date,"&end_date=",end_date,
"&facet_filter=true&api-key=",key, sep="")
initialQuery <- fromJSON(baseurl)
maxPages <- round((initialQuery$response$meta$hits[1] / 10)-1)
baseurl
fromJSON((baseurl))
fromJSON(baseurl)
library(httr)
library(jsonlite)
library(rjson)
library(tidyverse)
###########################################
key<-"c1b06598bf284957a1ddd98cdda82dff"
term <- "bill+clinton+monica" # Need to use + to string together separate words
begin_date <- "19890419"
end_date <- "20170901"
baseurl <- paste0("http://api.nytimes.com/svc/search/v2/articlesearch.json?q=",term,
"&begin_date=",begin_date,"&end_date=",end_date,
"&facet_filter=true&api-key=",key, sep="")
initialQuery <- fromJSON(baseurl)
maxPages <- round((initialQuery$response$meta$hits[1] / 10)-1)
GET(url)
fromJSON(baseurl)
library(RJSONIO)
key<-"c1b06598bf284957a1ddd98cdda82dff"
term <- "bill+clinton+monica" # Need to use + to string together separate words
begin_date <- "19890419"
end_date <- "20170901"
baseurl <- paste0("http://api.nytimes.com/svc/search/v2/articlesearch.json?q=",term,
"&begin_date=",begin_date,"&end_date=",end_date,
"&facet_filter=true&api-key=",key, sep="")
initialQuery <- fromJSON(baseurl)
maxPages <- round((initialQuery$response$meta$hits[1] / 10)-1)
initialQuery$response
initialQuery$response$meta
initialQuery$response$meta$hits
initialQuery$response$meta["hits"]
initialQuery$response$meta["hits"][1]
initialQuery <- fromJSON(baseurl)
maxPages <- round((initialQuery$response$meta["hits"][1] / 10)-1)
maxPages
if (maxPages>20){
maxPages<-20
pages <- list()
for(i in 0:maxPages){
nytSearch <- fromJSON(paste0(baseurl, "&page=", i), flatten = TRUE) %>% data.frame()
message("Retrieving page ", i)
pages[[i+1]] <- nytSearch
Sys.sleep(1)
}
}
maxPages
initialQuery <- fromJSON(baseurl)
maxPages <- round((initialQuery$response$meta["hits"][1] / 10)-1)
maxPages
str(maxPages)
str(maxPages[1])
str(as.numeric(maxPages[1]))
as.numeric(maxPages[1])
initialQuery <- fromJSON(baseurl)
maxPages <- round((as.numeric(initialQuery$response$meta["hits"][1]) / 10)-1)
maxPages
if (maxPages>20){
maxPages<-20
pages <- list()
for(i in 0:maxPages){
nytSearch <- fromJSON(paste0(baseurl, "&page=", i), flatten = TRUE) %>% data.frame()
message("Retrieving page ", i)
pages[[i+1]] <- nytSearch
Sys.sleep(1)
}
}
maxPages
initialQuery <- fromJSON(baseurl)
maxPages <- round((as.numeric(initialQuery$response$meta["hits"][1]) / 10)-1)
maxPages
if (maxPages>20){
maxPages<-20
pages <- list()
for(i in 0:maxPages){
nytSearch <- fromJSON(paste0(baseurl, "&page=", i), flatten = TRUE) %>% data.frame()
message("Retrieving page ", i)
pages[[i+1]] <- nytSearch
Sys.sleep(1)
}
}
allNYTSearch <- rbind_pages(pages)
# Visualize coverage by section
allNYTSearch %>%
group_by(response.docs.type_of_material) %>%
summarize(count=n()) %>%
mutate(percent = (count / sum(count))*100) %>%
ggplot() +
geom_bar(aes(y=percent, x=response.docs.type_of_material, fill=response.docs.type_of_material), stat = "identity") + coord_flip()
initialQuery <- fromJSON(baseurl)
maxPages <- round((initialQuery$response$meta$hits[1] / 10)-1)
history
history()
library(httr)
library(jsonlite)
library(rjson)
library(tidyverse)
#library(RJSONIO)
key<-"c1b06598bf284957a1ddd98cdda82dff"
term <- "bill+clinton+monica" # Need to use + to string together separate words
begin_date <- "19890419"
end_date <- "20170901"
baseurl <- paste0("http://api.nytimes.com/svc/search/v2/articlesearch.json?q=",term,
"&begin_date=",begin_date,"&end_date=",end_date,
"&facet_filter=true&api-key=",key, sep="")
initialQuery <- fromJSON(baseurl)
maxPages <- round((initialQuery$response$meta$hits[1] / 10)-1)
initialQuery <- fromJSON(getURL(baseurl))
initialQuery <- fromJSON(GET(baseurl))
initialQuery <- fromJSON(baseurl)
maxPages <- round((initialQuery$response$meta$hits[1] / 10)-1)
initialQuery <- fromJSON(baseurl)
maxPages <- round((initialQuery$response$meta$hits[1] / 10)-1)
initialQuery$response$meta
str(initialQuery$response$meta)
initialQuery$response$meta$hits
initialQuery$response$meta["hits"]
initialQuery$response$meta["hits"][[1]]
initialQuery <- fromJSON(baseurl)
maxPages <- round((initialQuery$response$meta["hits"][[1]] / 10)-1)
maxPages
if (maxPages>20){
maxPages<-20
pages <- list()
for(i in 0:maxPages){
nytSearch <- fromJSON(paste0(baseurl, "&page=", i), flatten = TRUE) %>% data.frame()
message("Retrieving page ", i)
pages[[i+1]] <- nytSearch
Sys.sleep(1)
}
}
fromJSON(paste0(baseurl, "&page=", 12)
fromJSON(paste0(baseurl, "&page=", 12), flatten = TRUE)
maxPages<-20
for(i in 0:maxPages){
nytSearch <- fromJSON(paste0(baseurl, "&page=", i), flatten = TRUE) %>% data.frame()
message("Retrieving page ", i)
pages[[i+1]] <- nytSearch
Sys.sleep(1)
}
if (maxPages>20){
maxPages<-20
pages <- list()
for(i in 0:maxPages){
nytSearch <- fromJSON(paste0(baseurl, "&page=", i), flatten = TRUE) %>% data.frame()
message("Retrieving page ", i)
pages[[i+1]] <- nytSearch
Sys.sleep(1)
}
}
allNYTSearch <- rbind_pages(pages)
allNYTSearch %>%
group_by(response.docs.type_of_material) %>%
summarize(count=n()) %>%
mutate(percent = (count / sum(count))*100) %>%
ggplot() +
geom_bar(aes(y=percent, x=response.docs.type_of_material, fill=response.docs.type_of_material), stat = "identity") + coord_flip()
initialQuery <- fromJSON(baseurl)
maxPages <- round((initialQuery$response$meta["hits"][[1]] / 10)-1)
if (maxPages>20){
maxPages<-20
pages <- list()
for(i in 0:maxPages){
nytSearch <- fromJSON(paste0(baseurl, "&page=", i), flatten = TRUE) %>% data.frame()
message("Retrieving page ", i)
pages[[i+1]] <- nytSearch
Sys.sleep(1)
}
}
library(httr)
#library(jsonlite)
library(rjson)
library(tidyverse)
#library(RJSONIO)
key<-"c1b06598bf284957a1ddd98cdda82dff"
term <- "bill+clinton+monica" # Need to use + to string together separate words
begin_date <- "19890419"
end_date <- "20170901"
baseurl <- paste0("http://api.nytimes.com/svc/search/v2/articlesearch.json?q=",term,
"&begin_date=",begin_date,"&end_date=",end_date,
"&facet_filter=true&api-key=",key, sep="")
initialQuery <- fromJSON(baseurl)
maxPages <- round((initialQuery$response$meta["hits"][[1]] / 10)-1)
if (maxPages>20){
maxPages<-20
pages <- list()
for(i in 0:maxPages){
nytSearch <- fromJSON(paste0(baseurl, "&page=", i), flatten = TRUE) %>% data.frame()
message("Retrieving page ", i)
pages[[i+1]] <- nytSearch
Sys.sleep(1)
}
}
allNYTSearch <- rbind_pages(pages)
allNYTSearch
maxpages<-20
pages <- list()
for(i in 0:maxPages){
nytSearch <- fromJSON(paste0(baseurl, "&page=", i), flatten = TRUE) %>% data.frame()
message("Retrieving page ", i)
pages[[i+1]] <- nytSearch
Sys.sleep(1)
}
initialQuery <- fromJSON(baseurl)
maxPages <- round((initialQuery$response$meta$hits[1] / 10)-1)
library(httr)
library(jsonlite)
#library(rjson)
library(tidyverse)
key<-"c1b06598bf284957a1ddd98cdda82dff"
term <- "bill+clinton+monica" # Need to use + to string together separate words
begin_date <- "19890419"
end_date <- "20170901"
baseurl <- paste0("http://api.nytimes.com/svc/search/v2/articlesearch.json?q=",term,
"&begin_date=",begin_date,"&end_date=",end_date,
"&facet_filter=true&api-key=",key, sep="")
initialQuery <- fromJSON(baseurl)
maxPages <- round((initialQuery$response$meta$hits[1] / 10)-1)
initialQuery <- fromJSON(baseurl)
maxpages<-20
for(i in 0:maxPages){
nytSearch <- fromJSON(paste0(baseurl, "&page=", i), flatten = TRUE) %>% data.frame()
message("Retrieving page ", i)
pages[[i+1]] <- nytSearch
Sys.sleep(1)
}
head(fromJSON(paste0(baseurl, "&page=", 2), flatten = TRUE) %>% data.frame())
maxpages<-20
pages <- list()
for(i in 0:maxPages){
nytSearch <- fromJSON(paste0(baseurl, "&page=", i), flatten = TRUE) %>% data.frame()
message("Retrieving page ", i)
pages[[i+1]] <- nytSearch
Sys.sleep(1)
}
for(i in 0:maxPages){
nytSearch <- fromJSON(paste0(baseurl, "&page=", i)) %>% data.frame()
message("Retrieving page ", i)
pages[[i+1]] <- nytSearch
Sys.sleep(1)
}
fromJSON(paste0(baseurl, "&page=", 7), flatten = TRUE)
fromJSON(paste0(baseurl, "&page=", 7), flatten = TRUE)%>%as.data.frame()
fromJSON(paste0(baseurl, "&page=", 7), flatten = TRUE)%>%data.frame()
library(httr)
library(jsonlite)
#library(rjson)
library(tidyverse)
#library(RJSONIO)
###########################################
key<-"c1b06598bf284957a1ddd98cdda82dff"
term <- "bill+clinton+monica" # Need to use + to string together separate words
begin_date <- "19890419"
end_date <- "20170901"
baseurl <- paste0("http://api.nytimes.com/svc/search/v2/articlesearch.json?q=",term,
"&begin_date=",begin_date,"&end_date=",end_date,
"&facet_filter=true&api-key=",key, sep="")
maxpages<-20
pages <- list()
for(i in 0:maxPages){
nytSearch <- fromJSON(paste0(baseurl, "&page=", i), flatten = TRUE) %>% data.frame()
message("Retrieving page ", i)
pages[[i+1]] <- nytSearch
Sys.sleep(1)
}
fromJSON(paste0(baseurl, "&page=", 12), flatten = TRUE) %>% data.frame(unlist())
fromJSON(paste0(baseurl, "&page=", 12), flatten = TRUE) %>% unlist()%>%data.frame()
maxpages<-20
pages <- list()
for(i in 0:maxPages){
nytSearch <- fromJSON(paste0(baseurl, "&page=", i), flatten = TRUE) %>% unlist()%>%data.frame()
message("Retrieving page ", i)
pages[[i+1]] <- nytSearch
Sys.sleep(1)
}
allNYTSearch <- rbind_pages(pages)
# Visualize coverage by section
allNYTSearch %>%
group_by(response.docs.type_of_material) %>%
summarize(count=n()) %>%
mutate(percent = (count / sum(count))*100) %>%
ggplot() +
geom_bar(aes(y=percent, x=response.docs.type_of_material, fill=response.docs.type_of_material), stat = "identity") + coord_flip()
head(allNYTSearch)
key<-"c1b06598bf284957a1ddd98cdda82dff"
term <- "bill+clinton+monica" # Need to use + to string together separate words
begin_date <- "19890419"
end_date <- "20170901"
baseurl <- paste0("http://api.nytimes.com/svc/search/v2/articlesearch.json?q=",term,
"&begin_date=",begin_date,"&end_date=",end_date,
"&facet_filter=true&api-key=",key, sep="")
initialQuery <- fromJSON(baseurl)
maxPages <- round((initialQuery$response$meta$hits[1] / 10)-1)
if (maxPages>20){
maxPages<-20
pages <- list()
for(i in 0:maxPages){
nytSearch <- fromJSON(paste0(baseurl, "&page=", i), flatten = TRUE) %>% data.frame()
message("Retrieving page ", i)
pages[[i+1]] <- nytSearch
Sys.sleep(1)
}
}
allNYTSearch <- rbind_pages(pages)
# Visualize coverage by section
allNYTSearch %>%
group_by(response.docs.type_of_material) %>%
summarize(count=n()) %>%
mutate(percent = (count / sum(count))*100) %>%
ggplot() +
geom_bar(aes(y=percent, x=response.docs.type_of_material, fill=response.docs.type_of_material), stat = "identity") + coord_flip()
library(tidyverse)
library(jsonlite)
library(httr)
key<-"c1b06598bf284957a1ddd98cdda82dff"
term <- "bill+clinton+monica" # Need to use + to string together separate words
begin_date <- "19890419"
end_date <- "20170901"
baseurl <- paste0("http://api.nytimes.com/svc/search/v2/articlesearch.json?q=",term,
"&begin_date=",begin_date,"&end_date=",end_date,
"&facet_filter=true&api-key=",key, sep="")
initialQuery <- fromJSON(baseurl)
maxPages <- round((initialQuery$response$meta$hits[1] / 10)-1)
maxPages
if (maxPages>20){
maxPages<-20
pages <- list()
for(i in 0:maxPages){
nytSearch <- fromJSON(paste0(baseurl, "&page=", i), flatten = TRUE) %>% data.frame()
message("Retrieving page ", i)
pages[[i+1]] <- nytSearch
Sys.sleep(1)
}
}
allNYTSearch <- rbind_pages(pages)
# Visualize coverage by section
allNYTSearch %>%
group_by(response.docs.type_of_material) %>%
summarize(count=n()) %>%
mutate(percent = (count / sum(count))*100) %>%
ggplot() +
geom_bar(aes(y=percent, x=response.docs.type_of_material, fill=response.docs.type_of_material), stat = "identity") + coord_flip()
key<-"c1b06598bf284957a1ddd98cdda82dff"
term <- "steve+jobs+death" # Need to use + to string together separate words
begin_date <- "19890419"
end_date <- "20170901"
baseurl <- paste0("http://api.nytimes.com/svc/search/v2/articlesearch.json?q=",term,
"&begin_date=",begin_date,"&end_date=",end_date,
"&facet_filter=true&api-key=",key, sep="")
initialQuery <- fromJSON(baseurl)
maxPages <- round((initialQuery$response$meta$hits[1] / 10)-1)
if (maxPages>20){
maxPages<-20
pages <- list()
for(i in 0:maxPages){
nytSearch <- fromJSON(paste0(baseurl, "&page=", i), flatten = TRUE) %>% data.frame()
message("Retrieving page ", i)
pages[[i+1]] <- nytSearch
Sys.sleep(1)
}
}
allNYTSearch <- rbind_pages(pages)
allNYTSearch %>%
group_by(response.docs.type_of_material) %>%
summarize(count=n()) %>%
mutate(percent = (count / sum(count))*100) %>%
ggplot() +
geom_bar(aes(y=percent, x=response.docs.type_of_material, fill=response.docs.type_of_material), stat = "identity") + coord_flip()
